<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
		"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
	<title>Author: Islamiyat Osuolale</title>
</head>
<body style="color: rgb(173, 173, 173); background-color: rgb(20, 20, 20)">
<pre><code>
<span style="color: rgb(173, 173, 173);">/*&nbsp;

--&nbsp;Author:&nbsp;Islamiyat&nbsp;Osuolale

*/

</span><span style="color: rgb(107, 107, 107);">*********************************************************</span><span style="color: rgb(173, 173, 173);">
</span><span style="color: rgb(107, 107, 107);">*********************************************************</span><span style="color: rgb(173, 173, 173);">
&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="color: rgb(129, 178, 252);">Linear&nbsp;Regression&nbsp;Example&nbsp;in&nbsp;Spark&nbsp;2.x
</span><span style="color: rgb(107, 107, 107);">*********************************************************</span><span style="color: rgb(173, 173, 173);">
</span><span style="color: rgb(107, 107, 107);">*********************************************************</span><span style="color: rgb(173, 173, 173);">
--&nbsp;Download&nbsp;dataset

wget&nbsp;https://www.dropbox.com/s/gqt24tbxh0i68uy/happiness.csv

/*
--Start&nbsp;Spark&nbsp;Shell
*/

spark-shell&nbsp;--master&nbsp;yarn&nbsp;

//--&nbsp;Just&nbsp;a&nbsp;bunch&nbsp;of&nbsp;import&nbsp;statements,&nbsp;you&nbsp;can&nbsp;run&nbsp;these&nbsp;in&nbsp;a&nbsp;paste&nbsp;command

import&nbsp;org.apache.spark.sql.functions._
import&nbsp;org.apache.spark.ml.feature.{VectorAssembler}
import&nbsp;org.apache.spark.ml.Pipeline
import&nbsp;org.apache.spark.ml.regression.{LinearRegression}
import&nbsp;org.apache.spark.ml.tuning.{CrossValidator,&nbsp;CrossValidatorModel,&nbsp;ParamGridBuilder}
import&nbsp;org.apache.spark.ml.evaluation.{RegressionEvaluator}
import&nbsp;org.apache.spark.ml.param.ParamMap
import&nbsp;org.apache.spark.sql.types.{DoubleType}

/*
--&nbsp;Loading&nbsp;our&nbsp;CSV&nbsp;file,&nbsp;note&nbsp;the&nbsp;inferSchema&nbsp;option&nbsp;being&nbsp;set&nbsp;to&nbsp;true
*/

val&nbsp;data&nbsp;=&nbsp;spark.read
&nbsp;.format("csv")
&nbsp;.option("header",&nbsp;"true")
&nbsp;.load("hdfs://10.128.0.15:8020/BigData/happiness.csv")


/*
--&nbsp;Here&nbsp;we&nbsp;are&nbsp;just&nbsp;selecting&nbsp;two&nbsp;columns&nbsp;from&nbsp;our&nbsp;dataset&nbsp;--&gt;&nbsp;The&nbsp;happiness&nbsp;rank&nbsp;and&nbsp;happiness&nbsp;score
*/

val&nbsp;rank_score&nbsp;=&nbsp;data.select(col("Happiness&nbsp;Rank").cast(DoubleType),&nbsp;col("upperwhisker").cast(DoubleType),&nbsp;col("lowerwhisker").cast(DoubleType))


/*
--&nbsp;Next&nbsp;we&nbsp;split&nbsp;the&nbsp;dataset&nbsp;into&nbsp;training&nbsp;and&nbsp;test&nbsp;sets
--&nbsp;We&nbsp;use&nbsp;a&nbsp;randomSplit&nbsp;function&nbsp;with&nbsp;a&nbsp;split&nbsp;percentage&nbsp;of&nbsp;80%,&nbsp;and&nbsp;20%
--&nbsp;The&nbsp;second&nbsp;argument&nbsp;to&nbsp;the&nbsp;function&nbsp;is&nbsp;the&nbsp;seed,&nbsp;it&nbsp;is&nbsp;used&nbsp;to&nbsp;get&nbsp;the&nbsp;same&nbsp;random&nbsp;results&nbsp;every&nbsp;time
*/

val&nbsp;Array(trainingData,&nbsp;testData)&nbsp;=&nbsp;rank_score.randomSplit(Array(0.8,&nbsp;0.2),&nbsp;1111)&nbsp;

/*
###&nbsp;Machine&nbsp;Learning&nbsp;Steps&nbsp;###

--&nbsp;All&nbsp;the&nbsp;following&nbsp;steps&nbsp;will&nbsp;be&nbsp;the&nbsp;same&nbsp;for&nbsp;all&nbsp;machine&nbsp;learning&nbsp;problems

--&nbsp;Preparing&nbsp;features&nbsp;and&nbsp;labels&nbsp;

--&nbsp;We&nbsp;need&nbsp;to&nbsp;prepare&nbsp;our&nbsp;features&nbsp;and&nbsp;labels&nbsp;to&nbsp;supply&nbsp;it&nbsp;to&nbsp;our&nbsp;algorithm,&nbsp;in&nbsp;this&nbsp;case&nbsp;linear&nbsp;regression
--&nbsp;Remember&nbsp;features&nbsp;are&nbsp;the&nbsp;input&nbsp;data&nbsp;to&nbsp;our&nbsp;algorithm&nbsp;and&nbsp;labels&nbsp;are&nbsp;the&nbsp;values&nbsp;our&nbsp;algorithm&nbsp;is&nbsp;going&nbsp;to&nbsp;train&nbsp;the&nbsp;model&nbsp;to&nbsp;predict
--&nbsp;Features&nbsp;are&nbsp;also&nbsp;called&nbsp;independent&nbsp;variables
--&nbsp;Labels&nbsp;are&nbsp;also&nbsp;called&nbsp;dependent&nbsp;variables

--&nbsp;In&nbsp;our&nbsp;problem,&nbsp;we&nbsp;have&nbsp;two&nbsp;FEATURE,&nbsp;it&nbsp;is&nbsp;the&nbsp;upperwhisker&nbsp;and&nbsp;lowerwhisker
--&nbsp;We&nbsp;will&nbsp;predict&nbsp;the&nbsp;happiness&nbsp;rank,&nbsp;which&nbsp;becomes&nbsp;the&nbsp;LABEL

--&nbsp;We&nbsp;will&nbsp;pass&nbsp;an&nbsp;array&nbsp;to&nbsp;the&nbsp;InputCols&nbsp;with&nbsp;the&nbsp;name&nbsp;of&nbsp;all&nbsp;the&nbsp;features&nbsp;
--&nbsp;And&nbsp;we&nbsp;will&nbsp;simply&nbsp;give&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;output&nbsp;column

--&nbsp;Think&nbsp;of&nbsp;a&nbsp;VectorAssembler&nbsp;as&nbsp;an&nbsp;Array
--&nbsp;Vector&nbsp;assembler&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;package&nbsp;one&nbsp;feature&nbsp;or&nbsp;multiple&nbsp;features&nbsp;into&nbsp;a&nbsp;vector
--&nbsp;And&nbsp;this&nbsp;will&nbsp;be&nbsp;our&nbsp;features&nbsp;column
--&nbsp;We&nbsp;pass&nbsp;an&nbsp;array&nbsp;to&nbsp;inputCols&nbsp;with&nbsp;the&nbsp;name&nbsp;of&nbsp;all&nbsp;the&nbsp;features&nbsp;we&nbsp;want&nbsp;to&nbsp;assemble
*/

val&nbsp;assembler&nbsp;=&nbsp;new&nbsp;VectorAssembler()
.setInputCols(Array("upperwhisker",&nbsp;"lowerwhisker"))
.setOutputCol("assembled-features")

/*
--&nbsp;Next&nbsp;we&nbsp;will&nbsp;instantiate&nbsp;our&nbsp;algorithm,&nbsp;in&nbsp;this&nbsp;case&nbsp;linear&nbsp;regression,&nbsp;and&nbsp;set&nbsp;the&nbsp;features&nbsp;and&nbsp;label&nbsp;column
--&nbsp;In&nbsp;this&nbsp;case,&nbsp;the&nbsp;features&nbsp;column&nbsp;will&nbsp;be&nbsp;the&nbsp;output&nbsp;from&nbsp;VectorAssembler&nbsp;which&nbsp;is&nbsp;the&nbsp;assembled&nbsp;features
--&nbsp;And&nbsp;label&nbsp;is&nbsp;the&nbsp;value&nbsp;linear&nbsp;regression&nbsp;will&nbsp;try&nbsp;to&nbsp;predict&nbsp;which&nbsp;is&nbsp;the&nbsp;happiness&nbsp;rank
--&nbsp;Features&nbsp;column&nbsp;will&nbsp;be&nbsp;the&nbsp;output&nbsp;form&nbsp;the&nbsp;vector&nbsp;assembler
*/

val&nbsp;lr&nbsp;=&nbsp;new&nbsp;LinearRegression()&nbsp;
&nbsp;.setFeaturesCol("assembled-features")
&nbsp;.setLabelCol("Happiness&nbsp;Rank")

/*
--&nbsp;Next&nbsp;we&nbsp;create&nbsp;a&nbsp;pipeline&nbsp;for&nbsp;everything&nbsp;that&nbsp;needs&nbsp;to&nbsp;be&nbsp;executed
--&nbsp;Think&nbsp;of&nbsp;the&nbsp;pipeline&nbsp;as&nbsp;the&nbsp;assembly&nbsp;line&nbsp;in&nbsp;the&nbsp;factory&nbsp;where&nbsp;all&nbsp;the&nbsp;parts&nbsp;for&nbsp;a&nbsp;product&nbsp;are&nbsp;assembled&nbsp;together
--&nbsp;This&nbsp;is&nbsp;what&nbsp;we&nbsp;are&nbsp;doing&nbsp;with&nbsp;pipeline
--&nbsp;We&nbsp;create&nbsp;STAGES&nbsp;in&nbsp;pipelines
--&nbsp;In&nbsp;this&nbsp;example,&nbsp;our&nbsp;pipeline&nbsp;has&nbsp;only&nbsp;two&nbsp;stages
--&nbsp;The&nbsp;first&nbsp;stage&nbsp;is&nbsp;where&nbsp;we&nbsp;assemble&nbsp;the&nbsp;features&nbsp;with&nbsp;VectorAssembler
--&nbsp;And&nbsp;the&nbsp;second&nbsp;stage,&nbsp;we'll&nbsp;specify&nbsp;the&nbsp;algorithm&nbsp;that&nbsp;is&nbsp;used&nbsp;to&nbsp;train&nbsp;the&nbsp;model
*/

val&nbsp;pipeline&nbsp;=&nbsp;new&nbsp;Pipeline()
&nbsp;.setStages(Array(assembler,&nbsp;lr))

/*
--&nbsp;Once&nbsp;we&nbsp;train&nbsp;the&nbsp;model,&nbsp;we&nbsp;need&nbsp;to&nbsp;evaluate&nbsp;the&nbsp;model&nbsp;for&nbsp;accuracy
--&nbsp;Since&nbsp;this&nbsp;is&nbsp;a&nbsp;regression&nbsp;problem,&nbsp;we&nbsp;will&nbsp;use&nbsp;RegressionEvaluator&nbsp;to&nbsp;evaluate&nbsp;the&nbsp;model
--&nbsp;The&nbsp;model,&nbsp;once&nbsp;it&nbsp;performs&nbsp;the&nbsp;predictions,&nbsp;it&nbsp;will&nbsp;store&nbsp;the&nbsp;prediction&nbsp;results&nbsp;in&nbsp;the&nbsp;prediction&nbsp;column
--&nbsp;Once&nbsp;a&nbsp;prediction&nbsp;is&nbsp;made,&nbsp;we&nbsp;need&nbsp;to&nbsp;evalue&nbsp;the&nbsp;prediction&nbsp;with&nbsp;the&nbsp;actual&nbsp;value,&nbsp;so&nbsp;we&nbsp;know&nbsp;how&nbsp;good&nbsp;the&nbsp;prediction&nbsp;is
--&nbsp;So&nbsp;in&nbsp;our&nbsp;case,&nbsp;our&nbsp;model&nbsp;will&nbsp;predict&nbsp;the&nbsp;ranking&nbsp;based&nbsp;on&nbsp;our&nbsp;score
--&nbsp;We&nbsp;need&nbsp;to&nbsp;see&nbsp;if&nbsp;the&nbsp;the&nbsp;prediction&nbsp;matches&nbsp;the&nbsp;actual&nbsp;or&nbsp;not
--&nbsp;If&nbsp;it&nbsp;doesn't&nbsp;match,&nbsp;we&nbsp;want&nbsp;to&nbsp;know&nbsp;how&nbsp;far&nbsp;the&nbsp;prediction&nbsp;is&nbsp;from&nbsp;the&nbsp;actual&nbsp;value
--&nbsp;We&nbsp;will&nbsp;use&nbsp;a&nbsp;metric&nbsp;called&nbsp;r&nbsp;squared&nbsp;to&nbsp;show&nbsp;the&nbsp;accuracy&nbsp;of&nbsp;the&nbsp;model&nbsp;prediction
--&nbsp;r&nbsp;squared&nbsp;is&nbsp;also&nbsp;called&nbsp;coefficient&nbsp;of&nbsp;determination
--&nbsp;r&nbsp;squared&nbsp;basically&nbsp;tells&nbsp;us&nbsp;how&nbsp;good&nbsp;our&nbsp;model&nbsp;is
--&nbsp;The&nbsp;higher&nbsp;the&nbsp;r2&nbsp;model&nbsp;the&nbsp;better&nbsp;our&nbsp;model
*/

val&nbsp;evaluator&nbsp;=&nbsp;new&nbsp;RegressionEvaluator()
&nbsp;.setLabelCol("Happiness&nbsp;Rank")
&nbsp;.setPredictionCol("prediction")
&nbsp;.setMetricName("r2")

/*
--&nbsp;Next&nbsp;we&nbsp;setup&nbsp;our&nbsp;cross&nbsp;validator
--&nbsp;cross&nbsp;validator&nbsp;is&nbsp;an&nbsp;interesting&nbsp;concept
--&nbsp;We&nbsp;need&nbsp;to&nbsp;provide&nbsp;two&nbsp;things&nbsp;to&nbsp;the&nbsp;CrossValidator
--&nbsp;An&nbsp;estimator&nbsp;and&nbsp;an&nbsp;evaluator
--&nbsp;Estimator&nbsp;we&nbsp;provide&nbsp;the&nbsp;pipeline
--&nbsp;For&nbsp;the&nbsp;evaluator&nbsp;we&nbsp;provide&nbsp;regression&nbsp;evaluator&nbsp;
--&nbsp;We&nbsp;can&nbsp;provide&nbsp;additional&nbsp;parameters&nbsp;called&nbsp;"hyper&nbsp;parameters"&nbsp;which&nbsp;can&nbsp;be&nbsp;used&nbsp;for&nbsp;tuning&nbsp;our&nbsp;model
--&nbsp;We&nbsp;don't&nbsp;have&nbsp;any&nbsp;hyper&nbsp;parameters&nbsp;so&nbsp;we&nbsp;create&nbsp;an&nbsp;instance&nbsp;of&nbsp;the&nbsp;parameter&nbsp;Grid&nbsp;Builder&nbsp;and&nbsp;call&nbsp;the&nbsp;build&nbsp;method
--&nbsp;This&nbsp;will&nbsp;provide&nbsp;an&nbsp;empty&nbsp;parameter&nbsp;map
--&nbsp;Finally&nbsp;we&nbsp;specify&nbsp;the&nbsp;fold&nbsp;as&nbsp;3
--&nbsp;This&nbsp;means&nbsp;the&nbsp;cross&nbsp;validator&nbsp;will&nbsp;generate&nbsp;three&nbsp;sets&nbsp;of&nbsp;data&nbsp;from&nbsp;our&nbsp;initial&nbsp;training&nbsp;dataset
--&nbsp;In&nbsp;other&nbsp;words&nbsp;it&nbsp;"folds"&nbsp;the&nbsp;data&nbsp;into&nbsp;3&nbsp;and&nbsp;from&nbsp;each&nbsp;sets&nbsp;of&nbsp;data,&nbsp;it&nbsp;will&nbsp;use&nbsp;2/3&nbsp;of&nbsp;the&nbsp;data&nbsp;for&nbsp;training&nbsp;and&nbsp;1/3&nbsp;of&nbsp;the&nbsp;data&nbsp;for&nbsp;testing
--&nbsp;And&nbsp;then&nbsp;it&nbsp;will&nbsp;fix&nbsp;the&nbsp;model&nbsp;based&nbsp;on&nbsp;the&nbsp;best&nbsp;accuracy&nbsp;based&nbsp;on&nbsp;the&nbsp;defined&nbsp;evaluation&nbsp;metric,&nbsp;in&nbsp;our&nbsp;case&nbsp;r2
*/

val&nbsp;cross_validator&nbsp;=&nbsp;new&nbsp;CrossValidator()
&nbsp;.setEstimator(pipeline)
&nbsp;.setEvaluator(evaluator)
&nbsp;.setEstimatorParamMaps(new&nbsp;ParamGridBuilder().build)
&nbsp;.setNumFolds(3)

/*
--&nbsp;Next&nbsp;we&nbsp;call&nbsp;fit&nbsp;on&nbsp;the&nbsp;cross&nbsp;validator&nbsp;passing&nbsp;our&nbsp;training&nbsp;dataset
--&nbsp;CrossValidator&nbsp;will&nbsp;now&nbsp;fold&nbsp;the&nbsp;dataset&nbsp;into&nbsp;3,&nbsp;divide&nbsp;each&nbsp;subset&nbsp;into&nbsp;training&nbsp;and&nbsp;test&nbsp;set
--&nbsp;Inside&nbsp;each&nbsp;fold,&nbsp;it&nbsp;will&nbsp;use&nbsp;the&nbsp;training&nbsp;set&nbsp;to&nbsp;train&nbsp;and&nbsp;test&nbsp;set&nbsp;to&nbsp;evaluate&nbsp;the&nbsp;model&nbsp;based&nbsp;on&nbsp;r2
--&nbsp;The&nbsp;best&nbsp;of&nbsp;the&nbsp;three&nbsp;models&nbsp;is&nbsp;returned
*/

val&nbsp;cvModel&nbsp;=&nbsp;cross_validator.fit(trainingData)

/*
--&nbsp;Now&nbsp;cvModel&nbsp;is&nbsp;a&nbsp;trained&nbsp;model&nbsp;that&nbsp;we&nbsp;can&nbsp;use&nbsp;to&nbsp;make&nbsp;predictions
--&nbsp;We&nbsp;can&nbsp;actually&nbsp;save&nbsp;this&nbsp;model&nbsp;and&nbsp;reuse&nbsp;it&nbsp;as&nbsp;well
--&nbsp;We'll&nbsp;see&nbsp;how&nbsp;to&nbsp;do&nbsp;that&nbsp;later

--&nbsp;Before&nbsp;we&nbsp;can&nbsp;use&nbsp;our&nbsp;model&nbsp;on&nbsp;the&nbsp;real&nbsp;data,&nbsp;let's&nbsp;test&nbsp;our&nbsp;data&nbsp;on&nbsp;the&nbsp;real&nbsp;data&nbsp;to&nbsp;see&nbsp;how&nbsp;good&nbsp;it&nbsp;is
--&nbsp;We&nbsp;now&nbsp;called&nbsp;cvModel.transform&nbsp;on&nbsp;the&nbsp;testData&nbsp;set
--&nbsp;when&nbsp;we&nbsp;call&nbsp;transform,&nbsp;our&nbsp;model&nbsp;will&nbsp;go&nbsp;over&nbsp;the&nbsp;dataset&nbsp;and&nbsp;make&nbsp;predictions
*/

val&nbsp;predictions&nbsp;=&nbsp;cvModel.transform(testData)

/*
--&nbsp;Remember,&nbsp;the&nbsp;directory&nbsp;SHOULD&nbsp;NOT&nbsp;EXIST,&nbsp;remove&nbsp;it&nbsp;first&nbsp;if&nbsp;it&nbsp;does
--&nbsp;hadoop&nbsp;fs&nbsp;-rm&nbsp;-r&nbsp;/BigData/happiness/output/
--&nbsp;Once&nbsp;the&nbsp;model&nbsp;has&nbsp;made&nbsp;predictions,&nbsp;we&nbsp;are&nbsp;just&nbsp;selecting&nbsp;the&nbsp;"Happiness&nbsp;Rank",&nbsp;&ldquo;upperwhiskey&rdquo;&nbsp;,&nbsp;&ldquo;lowerwhisker&rdquo;&nbsp;and&nbsp;the&nbsp;prediction&nbsp;column&nbsp;from&nbsp;the&nbsp;model
--&nbsp;and&nbsp;write&nbsp;it&nbsp;as&nbsp;a&nbsp;CSV&nbsp;file&nbsp;in&nbsp;a&nbsp;location&nbsp;in&nbsp;HDFS
*/

predictions
&nbsp;.select(col("Happiness&nbsp;Rank"),&nbsp;col("upperwhisker"),&nbsp;&nbsp;col("lowerwhisker"),&nbsp;col("prediction"))
&nbsp;.write
&nbsp;.format("csv")
&nbsp;.option("header",&nbsp;"true")
&nbsp;.save("hdfs://10.128.0.15:8020/BigData/happiness/output/")

/*
--&nbsp;Finally,&nbsp;we&nbsp;call&nbsp;the&nbsp;evaluator&nbsp;method&nbsp;on&nbsp;the&nbsp;evaluator&nbsp;passing&nbsp;the&nbsp;preditions&nbsp;DataFrame
--&nbsp;It&nbsp;will&nbsp;give&nbsp;us&nbsp;back&nbsp;the&nbsp;r2&nbsp;result
--&nbsp;R2&nbsp;is&nbsp;presented&nbsp;as&nbsp;a&nbsp;percentage,&nbsp;if&nbsp;we&nbsp;get&nbsp;0.9,&nbsp;means&nbsp;our&nbsp;model&nbsp;is&nbsp;90%&nbsp;accurate
*/

val&nbsp;r2&nbsp;=&nbsp;evaluator.evaluate(predictions)

println("r-squared&nbsp;on&nbsp;test&nbsp;data&nbsp;=&nbsp;"&nbsp;+&nbsp;r2)</span></code></pre></body>
</html>
